{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qnlx7PT04qVR"},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","import torchvision\n","from torchvision import datasets\n","from torchvision import transforms\n","from torchvision.transforms import ToTensor\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwhFyIb7wtCw"},"outputs":[],"source":["print(torch.__version__ )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"czU7N_ZYw-po"},"outputs":[],"source":["#The datasets we will be using is FashionMNISH from torchvision.datasets\n","train_data = datasets.FashionMNIST(\n","    root = \"data\",#where to download data to\n","    download = True ,#whether we want to download the data\n","    train = True ,#whether we need training data or testing data\n","    transform = ToTensor(),#converting the image into the numbers(Tensor)\n","    target_transform=None#how do we want to transform the labels\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"opI0aFXKzXek"},"outputs":[],"source":["test_data = datasets.FashionMNIST(\n","    root = \"data\",\n","    download = True ,\n","    train = False ,\n","    target_transform = None ,\n","    transform=ToTensor(),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"klrB4a0d0s7h"},"outputs":[],"source":["len(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_reNFzLO1fJ5"},"outputs":[],"source":["class_names = train_data.classes\n","class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Whowtx131hSX"},"outputs":[],"source":["image , label= train_data[0]\n","image , image.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o0-cbjOO1w8W"},"outputs":[],"source":["train_data.classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxwLgPbgDd_t"},"outputs":[],"source":["train_data.class_to_idx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8y2_TvsHEZZd"},"outputs":[],"source":["plt.imshow(image.squeeze() , cmap = \"gray\")\n","plt.title(class_names[label])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e6yE3WwgEbNa"},"outputs":[],"source":["torch.manual_seed(42)\n","fig = plt.figure(figsize = (9,9))\n","rows , cols = 4,4\n","for i in range(1 , rows*cols+1):\n","  random_index = torch.randint(0 ,len(train_data) , size = [1]).item()\n","  image , label = train_data[random_index]\n","  fig.add_subplot(rows , cols , i)\n","  plt.imshow(image.squeeze() , cmap = \"gray\")\n","  plt.title(class_names[label])"]},{"cell_type":"markdown","metadata":{"id":"IqWk0E52aXO4"},"source":["###PREPARE DATALOADERS\n","\n","DataLoader turns our data into Python Iterable\n","Now our data is in the form of Python Iterable\n","\n","Now we should convert our huge amount of data into data batches\n","\n","Reasons for converting into Mini Batches\n","1.It gives our NN a time to update its gradient\n","2.Our computer wont be able to process this amount of data at a time\n","3.So we will split the 60000 training data set into each set containing 32 , A mini batch contains 32 datum\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BqqyJzXRPrp6"},"outputs":[],"source":["#Prepare Data Loaders\n","from torch.utils.data import DataLoader\n","train_dataloader = DataLoader(shuffle = True , batch_size = 32 ,dataset = train_data)\n","\n","test_dataloader = DataLoader(shuffle = False , batch_size = 32 , dataset = test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VmkhNtYhcqej"},"outputs":[],"source":["train_dataloader.batch_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6bmV310ZbeHN"},"outputs":[],"source":["print(f'The length of the Train Data Loader {len(train_dataloader)} and the size of batch is {train_dataloader.batch_size}')\n","\n","print(f'The length of the Test Data Loader {len(test_dataloader)} and the size of batch is {test_dataloader.batch_size}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tm7Je2ZWdlsT"},"outputs":[],"source":["train_dataloader_image , train_dataloader_labels = next(iter(train_dataloader))\n","train_dataloader_image.shape , train_dataloader_labels.shape\n","print(len(train_dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RQjllXgueP1d"},"outputs":[],"source":["train_dataloaderimage , train_dataloaderlabel = next(iter(train_dataloader))\n","random_idx = torch.randint(0 , len(train_dataloader_image) , size = [1]).item()\n","img , label = train_dataloaderimage[random_idx] , train_dataloaderlabel[random_idx]\n","plt.imshow(img.squeeze() , cmap = \"gray\")\n","plt.title(class_names[label])\n","plt.axis = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wLVs7_QKIH0q"},"outputs":[],"source":["x = train_dataloader_image[0]\n","x.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XF4OVwiYIMJN"},"outputs":[],"source":["#Now we arw going to build a base line model\n","#Now we have to use a Flatten Layer\n","flatten = nn.Flatten()\n","output = flatten(x)\n","print(f'The shape before flattening is {x.shape}')\n","#So the shape before flattening is [color_channels , height , width]\n","print(f'The shape after flattening is {output.shape}')\n","#After flattening the shape is [color_channels , (height*Width)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J5sv6cjL2bqQ"},"outputs":[],"source":["print(f'The Number of batches in the Training DataLoader : {train_dataloader.batch_size}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pFZPOzVVIsky"},"outputs":[],"source":["from torch import nn\n","class FashionMNISTmodel(nn.Module):\n","  def __init__(self,\n","               input_shape : int ,\n","               hidden_units : int ,\n","               output_shape : int):\n","    super().__init__()\n","    self.layer_stack = nn.Sequential(\n","        nn.Flatten(),\n","        nn.Linear(\n","            in_features = input_shape ,\n","            out_features = hidden_units ,\n","        ),\n","        nn.Linear(in_features= hidden_units ,\n","                  out_features = output_shape)\n","    )\n","  def forward(self , x) :\n","    return self.layer_stack(x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7mg9WHIfNhRN"},"outputs":[],"source":["model = FashionMNISTmodel(\n","    input_shape = 28 * 28 ,\n","    hidden_units = 10 ,\n","    output_shape= len(class_names)\n",").to(\"cpu\")\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdFfhCTsPsJk"},"outputs":[],"source":["loss_fun = nn.CrossEntropyLoss()\n","optim = torch.optim.SGD(\n","    params = model.parameters(),\n","    lr = 0.1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7aFrJWfsxj2"},"outputs":[],"source":["def accuracy_fn(y_true, y_pred):\n","    \"\"\"Calculates accuracy between truth labels and predictions.\n","\n","    Args:\n","        y_true (torch.Tensor): Truth labels for predictions.\n","        y_pred (torch.Tensor): Predictions to be compared to predictions.\n","\n","    Returns:\n","        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n","    \"\"\"\n","    correct = torch.eq(y_true, y_pred).sum().item()\n","    acc = (correct / len(y_pred)) * 100\n","    return acc"]},{"cell_type":"markdown","metadata":{"id":"fwvZhYtorMI8"},"source":["#Creating a function to time our experiment\n","Two of the main things what we will track is\n","1.Model Performance(Loss and Accuracy values)\n","2.How fast it runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZMyBPWoRopj"},"outputs":[],"source":["from timeit import default_timer as timer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6vEFB01cXWvZ"},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVJXyRewr3TU"},"outputs":[],"source":["def calculate_time(start : float ,\n","                   end : float ,\n","                   device : torch.device = device):\n","  total_time = end - start\n","  print('The total time taken is : {total_time} second')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6EaLqpNWXmdO"},"outputs":[],"source":["import torch.optim as optim\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5ZmycQisKTK"},"outputs":[],"source":["from tqdm.auto import tqdm\n","torch.manual_seed(42)\n","epochs = 3\n","time_start = timer()\n","for epoch in tqdm(range(epochs)):\n","  train_loss = 0\n","  train_accuracy = 0\n","  for batch , (X , y) in enumerate(train_dataloader):\n","    y_pred = model(X)\n","    loss = loss_fun(y_pred , y)\n","    train_loss += loss.item()\n","    accuracy = accuracy_fn(y_true = y , y_pred = y_pred.argmax(dim=1))\n","    train_accuracy += accuracy\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  train_loss /= len(train_dataloader)\n","  train_accuracy /= len(train_dataloader)\n","  print(f'The Train Loss : {train_loss:.4f} and the Train Accuray : {train_accuracy:.4f}')\n","  test_accuracy = 0\n","  test_loss = 0\n","  model.eval()\n","  with torch.inference_mode() :\n","    for X , y in test_dataloader :\n","      test_preds = model(X)\n","      loss = loss_fun(test_preds , y)\n","      test_loss += loss.item()\n","      accuracy = accuracy_fn(y_true = y , y_pred = test_preds.argmax(dim = 1))\n","      test_accuracy += accuracy\n","  test_loss /= len(test_dataloader)\n","  test_accuracy /= len(test_dataloader)\n","  print(f'The Test Loss : {test_loss:.4f} and the Test Accuracy : {test_accuracy:.4f}')\n","end_time = timer()\n","print(calculate_time(start = time_start , end = end_time))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"odzKBlaNXQRV"},"outputs":[],"source":["model_0_time = calculate_time(start = time_start , end = end_time)"]},{"cell_type":"code","source":["optimizer = optim.SGD(model.parameters(), lr=0.01)"],"metadata":{"id":"weBoAZrqygRS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GfQsfpbcMpnO"},"outputs":[],"source":["from tqdm.auto import tqdm\n","torch.manual_seed(42)\n","train_time_on_cpu = timer()\n","epochs = 3\n","for epoch in tqdm(range(epochs)) :\n","  train_loss = 0\n","  for batch , (X,y) in enumerate(train_dataloader) :\n","    model.train()\n","    y_preds = model(X)\n","    loss = loss_fun(y_preds , y)\n","    train_loss += loss.item()\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  train_loss /= len(train_dataloader)\n","  test_loss = 0\n","  test_acc = 0\n","  model.eval()\n","  with torch.inference_mode():\n","    for X , y in test_dataloader :\n","      test_preds = model(X)\n","      t_loss = loss_fun(test_preds , y)\n","      test_loss +=  t_loss.item()\n","      accuracy = accuracy_fn(y_true = y , y_pred = test_preds.argmax(dim = 1))\n","      test_acc += accuracy\n","    test_loss /= len(test_dataloader)\n","    test_acc /= len(test_dataloader)\n","  print(f'The TrainLoss : {train_loss:.4f} , TestLoss : {test_loss:.4f} , TestingAccuracy : {test_acc:.4f}')\n","end_time_on_cpu = timer()\n","print(f'The total time took to complete training and testing the model is : {end_time_on_cpu - train_time_on_cpu}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UbNJMRf44Gns"},"outputs":[],"source":["from timeit import default_timer as timer\n","from tqdm.auto import tqdm\n","def eval_model(model : torch.nn.Module ,\n","               loss_fun : torch.nn.Module ,\n","               data : torch.utils.data.DataLoader ,\n","               accuracy_fn) :\n","  test_loss = 0\n","  test_accuracy = 0\n","  model.eval()\n","  with torch.inference_mode():\n","    for X , y in tqdm(data) :\n","      test_preds = model(X)\n","      loss = loss_fun(test_preds , y)\n","      test_loss += loss.item()\n","      test_accuracy += accuracy_fn(y_true = y , y_pred = test_preds.argmax(dim = 1))\n","    test_loss /= len(data)\n","    test_accuracy /= len(data)\n","    return {\"Model_name\" : model.__class__.__name__ ,\n","            \"Model_loss\" : test_loss ,\n","            \"Model_accuracy\" : test_accuracy}\n","model0_results = eval_model(model = model , loss_fun = loss_fun , data = test_dataloader , accuracy_fn = accuracy_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4f8pcq1LSy-H"},"outputs":[],"source":["model0_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9zQ7xWjITE_0"},"outputs":[],"source":["\n","print(len(train_data) + len(test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJ7R59RVT7jD"},"outputs":[],"source":["!nvidia-smi\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_02d0PZuWK4S"},"outputs":[],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a6DklaqoWQiv"},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UEHGTdVgWWyo"},"outputs":[],"source":["device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAw6yrNBceG1"},"outputs":[],"source":["from torch import nn"]},{"cell_type":"markdown","metadata":{"id":"lPY1zBojYnsr"},"source":["###SECOND MODEL , WE ARE GOING TO BUILD AN ANOTHER MODEL , LINEAR AND NON LINEARITY . Our first model has only the Flatten Layer , and two of the Linear Layer but it performs a quite well and provides a good acuuracy . Now we will build a second model with a activation function RELU . This phase is called Experimentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDU8olUKWdXb"},"outputs":[],"source":["class FashionMNISTNon(nn.Module) :\n","  def __init__(self ,\n","               input_shape : int ,\n","               hidden_units : int ,\n","               output_shape : int):\n","    super().__init__()\n","    self.layer_stack = nn.Sequential(\n","        nn.Flatten(),#which turns a tensor into a vector space\n","        nn.Linear(\n","            in_features = input_shape,\n","            out_features = output_shape\n","        ),\n","        nn.ReLU(),\n","        nn.Linear(\n","            in_features = hidden_units ,\n","            out_features = output_shape\n","        ),\n","        nn.ReLU()\n","    )\n","  def forward(self , x : torch.Tensor):\n","    return self.layer_stack(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SLntQlj-caeJ"},"outputs":[],"source":["device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWfSB9kAdbAm"},"outputs":[],"source":["class_names = train_data.classes\n","class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D28J0hq4dmpA"},"outputs":[],"source":["\n","class_index = train_data.class_to_idx\n","class_index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QxJ5m1A1clIh"},"outputs":[],"source":["\n","#Creating the instance of the new model\n","torch.manual_seed(42)\n","model_1 = FashionMNISTNon(\n","    input_shape = 28*28 ,\n","    hidden_units = 10 ,\n","    output_shape = len(class_names)\n",").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C9ZtVucgc19l"},"outputs":[],"source":["next(model_1.parameters()).device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IgEo5YTXy_1p"},"outputs":[],"source":["#Picking up a loss function , optimizer for our second model\n","loss_function = nn.CrossEntropyLoss() #measures how wrong out model is\n","optimizer = torch.optim.SGD(params = model_1.parameters() , lr = 0.1) #this imporoves the model's parameters which reduces the loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g7tChzgj1-Yz"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","train_dataloader = DataLoader(shuffle = True , batch_size = 32 , dataset = train_data)\n","test_dataloader = DataLoader(shuffle = True , batch_size = 32 , dataset = test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"we6o3P_42XQN"},"outputs":[],"source":["print(f'The Batch size of the Train DataLoader : {train_dataloader.batch_size}')\n","print(f'The Batch size of the Test Dataloader : {test_dataloader.batch_size}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LgKNi3N82qOZ"},"outputs":[],"source":["print(f'The number of batches in the Train Dataloader {len(train_data) / train_dataloader.batch_size}')\n","print(f'The number of batches in the Test Dataloader : {len(test_data) / test_dataloader.batch_size}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N8MwRS__28hr"},"outputs":[],"source":["print(f'Therefore the total samples in the train data loader : {train_dataloader.batch_size * 1875}')\n","sum_1 = train_dataloader.batch_size * 1875\n","print(f'Therefore the total samples in the test data loader : {test_dataloader.batch_size * 312.5}')\n","sum_2 = test_dataloader.batch_size * 312.5\n","total_sum = sum_1 + sum_2\n","print(f'Therefore the total samples are : {total_sum}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_S6EcL3Qz2GW"},"outputs":[],"source":["#Picking up evaluation metrics\n","def accuracy_fn(y_true, y_pred):\n","    correct = torch.eq(y_true, y_pred).sum().item()\n","    acc = (correct / len(y_pred)) * 100\n","    return acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PbbY6QZA6jtw"},"outputs":[],"source":["from timeit import default_timer as timer\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uC176pgP0hVT"},"outputs":[],"source":["\n","def train_step(\n","    model : torch.nn.Module,\n","    train_data : torch.utils.data.DataLoader,\n","    optimizer : torch.optim.Optimizer ,\n","    loss_fun : torch.nn.Module ,\n","    accuracy_fn ,\n","    device :torch.device = device\n","):\n","  model.train()\n","  model.to(device)\n","  epochs = 4\n","  for epoch in tqdm(range(epochs)) :\n","    train_loss = 0\n","    train_accuracy = 0\n","    for batch , (X , y) in enumerate(train_dataloader):\n","      X  = X.to(device)\n","      y = y.to(device)\n","      train_preds = model(X)\n","      loss = loss_fun(train_preds , y)\n","      train_loss += loss.item()\n","      accuracy = accuracy_fn(y_true = y , y_pred = train_preds.argmax(dim = 1))\n","      train_accuracy += accuracy\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","    train_loss /= len(train_data)\n","    train_accuracy /= len(train_data)\n","    print(f'The Train Loss : {train_loss:.4f} and the Train Accuracy : {train_accuracy:.4f} for the Epoch {epoch+1}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzxwCw145ncP"},"outputs":[],"source":["train_step(\n","    model = model_1 ,\n","    train_data = train_dataloader ,\n","    optimizer = optimizer ,\n","    loss_fun = loss_function ,\n","    accuracy_fn= accuracy_fn ,\n","    device = device\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOY2BAPb9ln8"},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DKJbhEbT59V2"},"outputs":[],"source":["from tqdm.auto import tqdm\n","def test_step(model : torch.nn.Module ,\n","              test_data : torch.utils.data.DataLoader ,\n","              loss_fun : torch.nn.Module ,\n","              accuracy_fn ,\n","              device : torch.device = device):\n","  model.to(device)\n","  model.eval()\n","  test_loss = 0\n","  test_accuracy = 0\n","  with torch.inference_mode() :\n","    for batch , (X , y) in enumerate(test_data) :\n","      X = X.to(device)\n","      y = y.to(device)\n","      test_preds = model(X)\n","      loss = loss_fun(test_preds, y)\n","      test_loss += loss.item()\n","      accuracy = accuracy_fn(y_true = y , y_pred = test_preds.argmax(dim=1))\n","      test_accuracy += accuracy\n","    test_loss /= len(test_data)\n","    test_accuracy /= len(test_data)\n","    print(f'The Test Loss : {test_loss:.4f} and the Test Accuracy : {test_accuracy:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8Lkyw7f9hmW"},"outputs":[],"source":["test_step(model = model_1 , test_data = test_dataloader , loss_fun = loss_function , accuracy_fn = accuracy_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ox4nORH8-CCt"},"outputs":[],"source":["def eval_model1(model : torch.nn.Module ,\n","                data : torch.utils.data.DataLoader ,\n","                loss_fun : torch.nn.Module ,\n","                accuracy_fun ,\n","                device : torch.device = device ,\n","                ):\n","  test_loss = 0\n","  test_accuracy = 0\n","  model.to(device)\n","  model.eval()\n","  with torch.inference_mode() :\n","    for batch , (X , y) in enumerate(data) :\n","      X = X.to(device)\n","      y = y.to(device)\n","      test_preds = model(X)\n","      loss = loss_fun(test_preds , y)\n","      accuracy = accuracy_fun(y_true = y , y_pred = test_preds.argmax(dim = 1))\n","      test_loss += loss.item()\n","      test_accuracy += accuracy\n","    test_loss /= len(data)\n","    test_accuracy /= len(data)\n","    return {\n","        \"Model_name\" : model.__class__.__name__ ,\n","        \"Model_loss\": test_loss ,\n","        \"Model_accuracy\" : test_accuracy\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N-E10F7RCE5-"},"outputs":[],"source":["model1_results = eval_model1(model = model_1 , data = test_dataloader , loss_fun = loss_function , accuracy_fun=accuracy_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6vjD5GdCdqy"},"outputs":[],"source":["model1_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJxzM0TNCusK"},"outputs":[],"source":["###CONVOLUTIONAL NEURAL NETWORKS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2qHy-raz56B"},"outputs":[],"source":["class FashionMNISTcnn(nn.Module):\n","  def __init__(self ,\n","               input_shape : int ,\n","               hidden_units : int ,\n","               output_units : int ,\n","                            ):\n","    super().__init__()\n","    self.conv_block_1 = nn.Sequential(\n","        nn.Conv2d(\n","            in_channels = input_shape ,\n","            out_channels = hidden_units ,\n","            kernel_size = 3 ,\n","            stride = 1 ,\n","            padding = 1\n","        ),\n","        nn.ReLU(),\n","        nn.Conv2d(\n","            in_channels = hidden_units ,\n","            out_channels = hidden_units ,\n","            kernel_size = 3 ,\n","            stride = 1 ,\n","            padding = 1\n","        ),\n","        nn.MaxPool2d(kernel_size = 2),\n","    )\n","    self.conv_block_2 = nn.Sequential(\n","        nn.Conv2d(\n","            in_channels = hidden_units ,\n","            out_channels = hidden_units ,\n","            kernel_size = 3 ,\n","            stride = 1 ,\n","            padding = 1\n","        ),\n","        nn.ReLU(),\n","        nn.Conv2d(\n","            in_channels = hidden_units ,\n","            out_channels = hidden_units ,\n","            kernel_size = 3 ,\n","            stride = 1 ,\n","            padding = 1\n","        ),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size = 2),\n","    )\n","    self.classifier = nn.Sequential(\n","        nn.Flatten(),\n","        nn.Linear(\n","            in_features = hidden_units*7*7 ,\n","            out_features = output_units\n","        )\n","    )\n","\n","\n","  def forward(self , x):\n","    x = self.conv_block_1(x)\n","    #print(x.shape)\n","    x = self.conv_block_2(x)\n","    #print(x.shape)\n","    x = self.classifier(x)\n","    return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMhEjnao9B41"},"outputs":[],"source":["torch.manual_seed(42)\n","model_3 = FashionMNISTcnn(\n","    input_shape = 1 ,\n","    hidden_units = 10 ,\n","    output_units = len(class_names)\n",").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBWmkbIMjvsx"},"outputs":[],"source":["#Now let us pass some dummy tensor through our model and then will observe the changes in the Shape\n","plt.imshow(image.squeeze() , cmap= \"gray\")\n","dummy_tensor_image = torch.randn(size = (1 ,28 ,28))\n","model_3(dummy_tensor_image.unsqueeze(0).to(device))"]},{"cell_type":"markdown","metadata":{"id":"QjUtGUrcXKCz"},"source":["###STEPPING INTO CONV2D"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pn3bDDP5CT1K"},"outputs":[],"source":["torch.manual_seed(42)\n","images = torch.randn(size = (32 , 3 , 64 , 64))\n","test_image = images[0]\n","conv_layer = nn.Conv2d(\n","    in_channels = 3 ,\n","    out_channels = 10,\n","    kernel_size = 3,\n","    stride = 1 ,\n","    padding = 1\n",")"]},{"cell_type":"markdown","metadata":{"id":"BTIwJmigdRRS"},"source":["###STEPPING THROUGH nn.MaxPool2d()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_F_2qTxddQkP"},"outputs":[],"source":["#First let us pass our data into the Conv2d layer\n","conv_result = conv_layer(test_image)\n","print(f\"The shape of the Image after passing through Conv2d layer {conv_result.shape}\")\n","\n","#Now lets create a MaxPool2d layer\n","max_pool_layer = nn.MaxPool2d(kernel_size = 2)\n","after_max_pool = max_pool_layer(conv_result)\n","print(f\"The shape of the Image after passing through Conv2d Layer and MaxPool2d Layer is {after_max_pool.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJFqGyrOh0wD"},"outputs":[],"source":["#Example of working of MaxPool2d layer\n","#Let us create a random tensor with shape (2,2) and will set the kernel_size as 2 in the max_pool layer\n","torch.manual_seed(42)\n","max_pool_layer = nn.MaxPool2d(kernel_size = 2)\n","random_tensor = torch.randn(1,1,2,2)\n","#Here (1,1,2,2) , here 1 is the batch size , 1 is the color channels , 2 is the height , 2 is the width\n","#Now let us pass this random_tensor to the maxpool2d layer with a kernel_size = 2\n","\n","print(f\"The size of the random tensor before going to MaxPool2d layer : {random_tensor.shape}\")\n","print(random_tensor)\n","result_tensor_after_maxpool = max_pool_layer(random_tensor)\n","print(f\"The shape of the Random Tensor after passing from MaxPool2d layer {result_tensor_after_maxpool.shape}\")\n","print(f\"The maximum value from the Random_Tensor is {result_tensor_after_maxpool}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRa41igIcNPw"},"outputs":[],"source":["#Now let us create a dataloader for our CNN , by using DataLoader\n","\n","#This is for the Train Data\n","from torch.utils.data import DataLoader\n","cnn_train_data = DataLoader(shuffle = True , batch_size = 32 , dataset = train_data)\n","print(f\"The Batch size of the Train Data : {cnn_train_data.batch_size}\")\n","print(f\"The total length of the Train Data : {len(train_data)}\")\n","print(f\"So the each batch of our cnn train data has {len(train_data)/ cnn_train_data.batch_size} images\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"964v7_VgEJyr"},"outputs":[],"source":["#This is for the Test Data\n","cnn_test_data = DataLoader(shuffle = False , batch_size = 10 , dataset = test_data)\n","print(f\"The Batch Size of the Test Data contains {cnn_test_data.batch_size} batches\")\n","print(f\"The total length of the Test Data : {len(test_data)}\")\n","print(f\"So each batch in the CNN test_data has {len(test_data)/cnn_test_data.batch_size} images\")"]},{"cell_type":"markdown","metadata":{"id":"OiYdMgaRFLTi"},"source":["###Now we will setup a Loss Function and a Optimiser for our CNN Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JmInbOvEE7qW"},"outputs":[],"source":["import torch.optim as optim\n","#Accuracy function is used for Evaluation Metrics\n","def accuracy_fn(y_true, y_pred):\n","    correct = torch.eq(y_true, y_pred).sum().item()\n","    acc = (correct / len(y_pred)) * 100\n","    return acc\n","loss_function_cnn = nn.CrossEntropyLoss()\n","optimizer_cnn = optim.SGD(params = model_3.parameters() , lr = 0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7gMh584DGZBV"},"outputs":[],"source":["from tqdm.auto import tqdm\n","from timeit import default_timer as timer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_QGsbp9HFRh"},"outputs":[],"source":["def train_step_cnn(\n","    model : torch.nn.Module ,\n","    train_data : torch.utils.data.DataLoader ,\n","    loss_fun : torch.nn.Module ,\n","    optimizer : torch.optim.Optimizer ,\n","    accuracy_fn ,\n","    device : torch.device = device\n","):\n","  model.train()\n","  model.to(device)\n","  epochs = 6\n","  for epoch in tqdm(range(epochs)):\n","    train_loss = 0\n","    train_accuracy = 0\n","    for batch , (X,y) in enumerate(train_data):\n","      X = X.to(device)\n","      y = y.to(device)\n","      train_preds = model(X)\n","      loss = loss_fun(train_preds , y)\n","      train_loss += loss.item()\n","      accuracy = accuracy_fn(y_true = y , y_pred = train_preds.argmax(dim=1))\n","      train_accuracy += accuracy\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","    train_loss /= len(train_data)\n","    train_accuracy /= len(train_data)\n","    print(f\"EPOCH : {epoch+1}\")\n","    print(f\"The Train Loss is {train_loss:.4f}\")\n","    print(f\"The Train Accuracy is {train_accuracy:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LPSyXIigJeZe"},"outputs":[],"source":["def test_step_cnn(model : torch.nn.Module ,\n","                  test_data : torch.utils.data.DataLoader ,\n","                  loss_fun : torch.nn.Module ,\n","                  optimizer : torch.optim.Optimizer ,\n","                  accuracy_fn ,\n","                  device : torch.device = device):\n","  model.eval()\n","  model.to(device)\n","  with torch.inference_mode() :\n","      test_loss = 0\n","      test_accuracy = 0\n","      for batch , (X,y) in enumerate(test_data):\n","        X = X.to(device)\n","        y = y.to(device)\n","        y_preds = model(X)\n","        loss = loss_fun(y_preds , y)\n","        test_loss += loss.item()\n","        accuracy = accuracy_fn(y_true = y , y_pred = y_preds.argmax(dim=1))\n","        test_accuracy += accuracy\n","      test_loss /= len(test_data)\n","      test_accuracy /= len(test_data)\n","      print(f\"The Test Loss is {test_loss:.4f}\")\n","      print(f\"The Test Accuracy is {test_accuracy:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePusew0nK0EY"},"outputs":[],"source":["train_step_cnn(model = model_3 , train_data = cnn_train_data , loss_fun = loss_function_cnn , optimizer = optimizer_cnn , accuracy_fn=accuracy_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"llxIl5LqOMVe"},"outputs":[],"source":["\n","test_step_cnn(model = model_3 , test_data = cnn_test_data , loss_fun = loss_function_cnn , optimizer = optimizer_cnn , accuracy_fn=accuracy_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmW4BPcfOp6-"},"outputs":[],"source":["\n","def eval_step_cnn(model : torch.nn.Module ,\n","                  test_data : torch.utils.data.DataLoader ,\n","                  loss_fun : torch.nn.Module ,\n","                  optimizer : torch.optim.Optimizer ,\n","                  accuracy_fn ,\n","                  device : torch.device = device):\n","  model.eval()\n","  model.to(device)\n","  with torch.inference_mode() :\n","      test_loss = 0\n","      test_accuracy = 0\n","      for batch , (X,y) in enumerate(test_data):\n","        X = X.to(device)\n","        y = y.to(device)\n","        y_preds = model(X)\n","        loss = loss_fun(y_preds , y)\n","        test_loss += loss.item()\n","        accuracy = accuracy_fn(y_true = y , y_pred = y_preds.argmax(dim=1))\n","        test_accuracy += accuracy\n","      test_loss /= len(test_data)\n","      test_accuracy /= len(test_data)\n","      return {\n","          \"Model_name\" : model.__class__.__name__ ,\n","          \"Model_loss\" : test_loss ,\n","          \"Model_accuracy\" : test_accuracy\n","      }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x9V-Naq2S-ay"},"outputs":[],"source":["model_cnn_results = eval_step_cnn(model = model_3 , test_data = cnn_test_data, loss_fun=loss_function_cnn ,optimizer=optimizer_cnn , accuracy_fn= accuracy_fn )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jvnf_y7GTcnp"},"outputs":[],"source":["model0_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYllHxChTcam"},"outputs":[],"source":["model1_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PndGgHemTSPV"},"outputs":[],"source":["model_cnn_results"]},{"cell_type":"markdown","metadata":{"id":"kRKtkmktUuoW"},"source":["###COMPARING OUR MODEL RESULTS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P-m6JM30UuMN"},"outputs":[],"source":["import pandas as pd\n","compare_results = pd.DataFrame([\n","    model0_results,\n","    model1_results,\n","    model_cnn_results\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5vjkvcrTTzz"},"outputs":[],"source":["print(compare_results)"]},{"cell_type":"markdown","source":["###MAKE AND EVALUATE RANDOM PREDICTIONS"],"metadata":{"id":"icHKzfQozmwK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CnDWsdWjU9Zb"},"outputs":[],"source":["def make_predictions(\n","    model : torch.nn.Module ,\n","    data : list ,\n","    device : torch.device = device\n","):\n","  pred_probs = []\n","  model.to(device)\n","  model.eval()\n","  with torch.inference_mode():\n","    for sample in data :\n","      #Prepare a sample , add a batch dimension to the sample and send it to the model\n","      sample = torch.unsqueeze(sample , dim = 0).to(device)\n","\n","      #Forward pass to the Model\n","      pred_logit = model(sample)\n","\n","      #Get Prediction probability\n","      pred_prob = torch.softmax(pred_logit.squeeze() , dim = 0)\n","\n","      #Store the pred_prob in the pred_probs list\n","      pred_probs.append(pred_prob.cpu())\n","  return torch.stack(pred_probs)"]},{"cell_type":"code","source":["test_data\n","from matplotlib import pyplot as plt"],"metadata":{"id":"nR2oQuqC26hS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","test_samples = []\n","test_labels = []\n","\n","for sample , label in random.sample(list(test_data) , k = 9):\n","  test_samples.append(sample)\n","  test_labels.append(label)\n","\n","pred_probs = make_predictions(model = model_3 , data = test_samples)\n","pred_classes = pred_probs.argmax(dim = 1)\n","plt.figure(figsize = (9,9))\n","ncols = 3\n","nrows = 3\n","for i , sample in enumerate(test_samples):\n","  plt.subplot(nrows , ncols ,i+1)\n","  plt.imshow(sample.squeeze()  ,cmap = \"gray\")\n","  pred_label = class_names[pred_classes[i]]\n","  truth_label = class_names[test_labels[i]]\n","  title_text = f\"Pred:{pred_label}|Truth:{truth_label}\"\n","  if pred_label == truth_label:\n","    plt.title(title_text , color = \"green\" , fontsize = 10)\n","  else :\n","    plt.title(title_text , color = \"red\" , fontsize = 10)\n"],"metadata":{"id":"iRrbmurazlsd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install nbformat"],"metadata":{"id":"Kie09qXS7gtB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wskFLvNhsTro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YZtvKFj9tk4u"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1Cto1PBeoqWy7Fgma0Qwbc9g5HwPSxA54","timestamp":1753114703325},{"file_id":"1kE9YR3sPcwMcsjHC5AnT7P5-GcXUuwyf","timestamp":1753114171474}],"authorship_tag":"ABX9TyN0qdqHO9aFDE6hgY8KkmTX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}